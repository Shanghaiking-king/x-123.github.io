<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Xiaoyan Jiang | Academic Resume</title>
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gradient-to-br from-gray-900 via-gray-800 to-gray-700 text-gray-100 font-sans">

<body class="bg-gradient-to-b from-slate-100 to-slate-300 text-gray-800 font-sans">

  <!-- Navigation Bar -->
  <nav class="bg-indigo-700 text-white p-4">
  <div class="max-w-7xl mx-auto flex flex-wrap justify-between items-center">
    <a href="#home" class="text-2xl font-semibold mb-2 sm:mb-0">Xiaoyan Jiang</a>
    <div class="flex flex-wrap gap-4 text-sm">
      <a href="#bio" class="hover:text-indigo-300">Bio</a>
      <a href="#affiliations" class="hover:text-indigo-300">Affiliations</a>
      <a href="#education" class="hover:text-indigo-300">Education</a>
      <a href="#social" class="hover:text-indigo-300">Social</a>
      <a href="#teaching" class="hover:text-indigo-300">Teaching</a>
      <a href="#publications" class="hover:text-indigo-300">Selected Publications</a>
      <a href="#projects" class="hover:text-indigo-300">Projects</a>
      <a href="#patents" class="hover:text-indigo-300">Patents</a>
      <a href="#awards" class="hover:text-indigo-300">Honors & Awards</a>
      <a href="#service" class="hover:text-indigo-300">Service</a>
      <a href="#languages" class="hover:text-indigo-300">Languages</a>
    </div>
  </div>
</nav>

  <div class="max-w-5xl mx-auto p-8">

    <!-- Header + BIO Section Combined -->
    <section id="home" class="bg-white shadow-2xl rounded-2xl p-8 mb-10">
      <div class="flex gap-8 items-center mb-6">
        <img src="images/1.png" alt="Xiaoyan Jiang" class="w-30 h-30 rounded-full object-cover border-4 border-indigo-700">



        <div>
          <h1 class="text-4xl font-bold text-indigo-700 mb-2">Xiaoyan Jiang</h1>
          <p class="text-lg text-gray-600 mb-4">Associate Professor | Computer Vision & Machine Learning</p>
          <div class="flex flex-wrap gap-4 text-blue-700 text-sm underline mb-4">
  <a href="https://sky-visionx.github.io/" target="_blank">Homepage</a>
  <a href="https://scholar.google.com/citations?hl=zh-CN&user=pKnD8WcAAAAJ" target="_blank">Google Scholar</a>
  <a href="https://github.com/sky-visionX" target="_blank">GitHub</a>
  <a href="https://www.linkedin.com/in/xiaoyan-jiang-460682a0/?miniProfileUrn=urn%3Ali%3Afsd_profile%3AACoAABV04AgB-DQCIN21qpeag-g1Tpzy_7A-u0U" target="_blank">LinkedIn</a>
  <a href="https://dblp.org/pid/40/8839.html" target="_blank">DBLP</a>
  <a href="https://www.researchgate.net/profile/Xiaoyan-Jiang-2" target="_blank">ResearchGate</a>
</div>

          <div class="text-sm text-gray-700 space-y-1 mb-6">
            <p><strong>Address:</strong> Einsteinweg 55, 2333 CC Leiden, Netherlands</p>
            <p><strong>Phone:</strong> +31 0657171746</p>
            <p><strong>Email:</strong> xiaoyan.jiang@outlook.com | x.jiang@liacs.leidenuniv.nl</p>
          </div>
        </div>
      </div>

      <div class="border-t pt-4 mt-4">
        <h2 id="bio" class="text-2xl font-semibold text-blue-600 mb-4">BIO</h2>
        <p class="text-gray-700 leading-relaxed">
          I am an associate professor leading a computer vision group in SUES and the deputy director for industrialization of Artificial Intelligence (AI) models in Anhui Province, China. My research interests span computer vision and machine learning pursuing realizing vision and recognition abilities for robots. I was awarded twice for the contributions to video analysis and intelligent aerospace. I served as an associate editor for Applied Intelligence since 2014. Currently I am focusing on discovering the power of foundation models in downstream tasks.
        </p>
        <p class="mt-4 text-gray-700 leading-relaxed">
          I am good at analyzing existing problems and proposing effective solutions based on domain knowledge. I keep studying the state-of-the-art models and form my own understandings of AI trends. I have 60+ publications including top journals and conferences. I have led projects in inspection robots, image/video re-identification, and medical image segmentation. I am interested in exchanging ideas with experts in interdisciplinary subjects internationally.
        </p>
      </div>
    </section>

    <!-- Professional Affiliations -->
    <section id="affiliations" class="bg-white shadow-xl rounded-2xl p-6 mb-6">
      <h2 class="text-2xl font-semibold text-blue-600 border-b pb-2 mb-4">Professional Affiliations</h2>
      <ul class="list-disc pl-5 space-y-1 text-gray-700">
        <li>2024/10-2025/10 Visiting Scholar, Leiden Institute of Advanced Computer Science (LIACS),
Leiden University, Leiden, the Netherlands</li>
        <li>2020/1-Now Associate Professor, School of Electronic and Electrical Engineering,
Shanghai University of Engineering Science (SUES), Shanghai, China</li>
        <li>2016/7-2019/12 Assistant Professor, School of Electronic and Electrical Engineering,
Shanghai University of Engineering Science, Shanghai, China</li>
        <li>2022-Now             
Deputy Dean, Artificial Intelligence Industry Research Institute of SUES, Anhui, China</li>
        <li>2024-Now             
EDUCATION 
Associate Editor, Applied Intelligence, Springer, Electronic ISSN: 1573-7497,  
Print ISSN: 0924-669X, Science Citation Index Expanded (SCIE) </li>
      </ul>
    </section>

    <!-- Education -->
    <section id="education" class="bg-white shadow-xl rounded-2xl p-6 mb-6">
  <h2 class="text-2xl font-semibold text-blue-600 border-b pb-2 mb-4">Education</h2>
  <div class="space-y-6 text-gray-700">

    <!-- Doctoral Degree -->
    <div>
      <p class="font-semibold">Doctor in Engineering (Dr.-Ing.), Computer Science</p>
      <p class="text-sm text-gray-600">Friedrich-Schiller University, Jena, Germany | 2010/10 – 2015/12</p>
      <ul class="list-disc pl-5 mt-1 space-y-1 text-sm">
        <li>Supervisor: Prof. Dr.-Ing Joachim Denzler</li>
        <li>Dissertation: <em>Multi-object Tracking-by-Detection in Multi-Camera Systems</em></li>
      </ul>
    </div>

    <!-- Master's Degree -->
    <div>
      <p class="font-semibold">Master of Science</p>
      <p class="text-sm text-gray-600">China University of Mining and Technology | 2007/9 – 2010/7</p>
      <ul class="list-disc pl-5 mt-1 space-y-1 text-sm">
        <li>Graduated with distinction (Summa Cum Laude)</li>
        <li>Second-level university scholarship annually</li>
      </ul>
    </div>

    <!-- Bachelor's Degree -->
    <div>
      <p class="font-semibold">Bachelor of Information Engineering</p>
      <p class="text-sm text-gray-600">China University of Mining and Technology | 2003/9 – 2007/7</p>
      <ul class="list-disc pl-5 mt-1 text-sm">
        <li>Graduated with distinction (Summa Cum Laude)</li>
      </ul>
    </div>

  </div>
</section>


    <!-- Social Communications -->
    <section id="social" class="bg-white shadow-xl rounded-2xl p-6 mb-6">
  <h2 class="text-2xl font-semibold text-blue-600 border-b pb-2 mb-4">Social Communications</h2>
  <ul class="list-disc pl-5 space-y-4 text-gray-700 text-sm leading-relaxed">
    <li>
      <strong>2025/4/8</strong> – Presentation in <em>Monthly Academic Seminar</em>, LIACS, Leiden University, Netherlands<br>
      <strong>Title:</strong> Knowledge-augmented Semantic Segmentation in Computer Vision
    </li>
    <li>
      <strong>2025/2/28</strong> – Presentation in <em>Computational Imaging and Deep Learning (CIDL)</em>, LIACS, Leiden University, Netherlands<br>
      <strong>Title:</strong> Vision Foundation Model-based Crack Segmentation with Noisy Labels
    </li>
    <li>
      <strong>2025/1/29</strong> – Presentation within <em>Machine Learning Cluster</em>, LIACS, Leiden University, Netherlands<br>
      <strong>Title:</strong> Possibilities and Trends of Multi-modal Vision Perception of Machines<br>
      <a href="https://press.liacs.nl/ml2025/" class="text-blue-600 underline">Event Link</a>
    </li>
    <li>
      <strong>2024/10</strong> – Keynote Speaker, <em>International Conference on Pattern Recognition and Image Analysis (PRIA 2024)</em>, Nanjing, China<br>
      <strong>Title:</strong> Distribution-aware Noisy-label Crack Segmentation
    </li>
    <li>
      <strong>2023/12</strong> – Keynote Speaker, <em>14th Int'l Conference on Computational Intelligence and Software Engineering (CISE)</em>, Guilin, China<br>
      <strong>Title:</strong> Enhancing the Visual Perception Ability for Intelligent Systems<br>
      <a href="https://www.academicx.org/CISE2023/" class="text-blue-600 underline">Event Link</a>
    </li>
    <li>
      <strong>2021/2</strong> – Keynote Speaker, <em>International Workshop on Information Technology Convergence (IWITC)</em>, Korea (Online)<br>
      <strong>Title:</strong> 3D Object Detection, Multi-object Tracking, and Person Re-identification toward Scene Understanding
    </li>
    <li>
      <strong>2019/9</strong> – Keynote Speaker, <em>International Conference on Frontiers Technology of Information and Computer (ICFTIC2019)</em>, Dalian, China<br>
      <strong>Title:</strong> Depth Estimation, Multi-object Tracking, and Person Re-identification toward Scene Understanding
    </li>
    <li>
      <strong>2019/4</strong> – Invited Tutorial, <em>Key Concepts and Applications in Artificial Intelligence</em>, Shanghai Public Security University
    </li>
  </ul>
</section>


    <!-- Teaching -->
    <section id="teaching" class="bg-white shadow-xl rounded-2xl p-6 mb-6">
      <h2 class="text-2xl font-semibold text-blue-600 border-b pb-2 mb-4">Teaching</h2>
      <ul class="list-disc pl-5 space-y-2 text-gray-700">
        <li>Machine Learning (Bachelor), 2021-Now</li>
        <li>Computer Vision (Bachelor & Master), 2018-Now</li>
        <li>Digital Image Processing (Bachelor), 2017-2021</li>
        <li>C++ Programming (Bachelor), 2017-Now</li>
        <li>Supervised 24 graduate students and 1 PhD student</li>
        <li>List of past and current students: <a href="#" class="text-blue-600 underline">View here</a></li>
      </ul>
    </section>

<section id="publications" class="bg-white shadow-xl rounded-2xl p-6 mb-6">
  <h2 class="text-2xl font-semibold text-blue-600 border-b pb-2 mb-4">Selected Publications</h2>
  <h3 class="text-xl font-semibold text-gray-800 mt-4 mb-2">Recent arXiv Papers</h3>
  <ul class="list-disc pl-5 space-y-1 text-gray-700">
    <li>For some pre-prints, please see my <a href="https://arxiv.org/find/all/1/au:+jiang_xiaoyan/0/1/0/all/0/1?skip=0&query_id=fd7859c6c801598a" target="_blank" class="text-blue-600 underline">ArXiv</a> papers.</li>
    <li>[ArXiv 4] <strong>Project-and-Fuse</strong>: Improving RGB-D Semantic Segmentation via Graph Convolution Networks — Xiaoyan Jiang, Bohan Wang, Xinlong Wan, Shanshan Chen, Hamido Fujita*, Hanan Abd. Al Juaid</li>
    <li>[ArXiv 3] <strong>FlexiCrackNet</strong>: A Flexible Pipeline for Enhanced Crack Segmentation with General Features Transferred from SAM — Xinlong Wan, Xiaoyan Jiang∗, Guangsheng Luo, Jenq-Neng Hwang, Michael S. Lew</li>
    <li>[ArXiv 2] <strong>Distribution-aware Noisy-label Crack Segmentation</strong> — Xiaoyan Jiang, Xinlong Wan, Kaiying Zhu, Xihe Qiu, Zhijun Fang</li>
    <li>[ArXiv 1] <strong>CrackSegDiff</strong>: Diffusion Probability Model-based Multi-modal Crack Segmentation — Xiaoyan Jiang, Licheng Jiang, A Wang, Kaiying Zhu, Yongbin Gao</li>
  </ul>

  <h3 class="text-xl font-semibold text-gray-800 mt-6 mb-2">Main Full-Length Journal Publications</h3>
  <p class="text-gray-600 mb-2">For a complete list, please see my <a href="#" class="text-blue-600 underline">Google Scholar</a> page.</p>
  <ul class="list-disc pl-5 space-y-1 text-gray-700">
    <li>[J22] <strong>TV-Net</strong>: Structure-level Feature Fusion for Road Crack Segmentation — IEEE TITS, 2024.1</li>
    <li>[J21] Multi-Scale Pose Estimation with Hard Keypoint Mining — IEEE TSMC, 2024.3</li>
    <li>[J20] Prompt Generation using VL Pre-training Models — Pattern Recognition, 2024.3</li>
    <li>[J19] Adaptive Multimodal Prompt for HOI — Applied Intelligence, 2024</li>
    <li>[J18] Chinese Abstract-generation Model — ACM TALLIP, 2024</li>
    <li>[J17] SGAT-based Object Tracking — Applied Intelligence, 2023</li>
    <li>[J16] Cross-correlation GCN for Object Tracking — Symmetry, 2023</li>
    <li>[J15] Sparse Graph Wavelet CNN for Re-ID — Pattern Recognition, 2022</li>
    <li>[J14] Self-Attention Feature Learning for Re-ID — Knowledge-Based Systems, 2020</li>
    <li>[J13] Multi-Object Tracking in Sensor Networks — IEEE Access, 2018</li>
    <li>[J12] Multi-Marker Tracking in X-ray Videos — Signal Processing: Image Communication, 2017</li>
    <li>[J11] Automated Tracking in Cardiac Imaging — ICVTS, 2016</li>
    <li>[J10] ADR-Net for Medical Image Segmentation — Medical Physics, 2020</li>
    <li>[J9-J1] Numerous 3D vision works — Applied Intelligence, TOMM, Sensors, TITS, Knowledge-Based Systems, etc.</li>
  </ul>

  <h3 class="text-xl font-semibold text-gray-800 mt-6 mb-2">Peer-reviewed Conference Publications</h3>
  <ul class="list-disc pl-5 space-y-1 text-gray-700">
    <li>[C12] PTQ4RIS: Post-Training Quantization for Referring Segmentation — ICRA 2025</li>
    <li>[C11] TexLiverNet: Knowledge-enhanced Liver Tumor Segmentation — ISBI 2025</li>
    <li>[C10] LiDUT-Depth: Self-supervised Depth Estimation — ICPR 2024</li>
    <li>[C9] Global Fusion for Depth Estimation — ICONIP 2024</li>
    <li>[C8] ORB-SLAM3 with GNSS — ICITEE 2023</li>
    <li>[C7] Multi-modal Scene Depth Estimation — ICIP 2023</li>
    <li>[C6] Unsupervised Depth & Ego-motion — ICME 2019</li>
    <li>[C5] Self-Attention for Person Re-ID — ICONIP 2019</li>
    <li>[C4] MAP for Multi-Person Tracking — VISAPP 2014</li>
    <li>[C3] Multi-Marker Tracking in X-ray — CAIP 2013</li>
    <li>[C2] Tracking-by-Detection in Multi-Camera Systems — ICCVG 2012</li>
    <li>[C1] Data Association in Camera Networks — ICDSC 2012</li>
  </ul>
</section>

<section id="projects" class="bg-white shadow-xl rounded-2xl p-6 mb-6">
  <h2 class="text-2xl font-semibold text-blue-600 border-b pb-2 mb-4">Projects</h2>
  <ul class="list-disc pl-5 space-y-4 text-gray-700">
    <li>
      <strong>2021–2024</strong> — Key parameters extraction and states evaluation of airport pavement using multi-source data fusion, <em>Key Project, NSFC</em>, CNY: ¥2,100,000<br>
      <strong>Role:</strong> Tech Lead<br>
      ▪ Write proposal and raise the funding with Prof. Fang and Prof. Gao<br>
      ▪ Collaborate with Guimu Robot Co. Ltd. and Beijing Daxing International Airport<br>
      ▪ Coordinate project, lead meetings, ensure timely progress<br>
      ▪ Develop algorithms and supervise students (SLAM, VO, 3D compression, FOD detection)<br>
      ▪ Published in top journals including <em>TITS</em>, <em>PR</em>
    </li>
    <li>
      <strong>2018–2020</strong> — Data association of multi-object tracking and person re-ID in non-overlapping camera systems, <em>Youth Project, NSFC</em>, CNY: ¥240,000<br>
      <strong>Role:</strong> Principal Investigator<br>
      ▪ Write proposal and raise the funding<br>
      ▪ Collaborate with Prof. Hwang (University of Washington)<br>
      ▪ Develop graph-based models, domain adaptation, discriminant features<br>
      ▪ Early use of attention mechanisms for re-ID<br>
      ▪ Published in high-level journals and conferences
    </li>
    <li>
      <strong>04–11/2019</strong> — Intelligent fiber terminal state recognition, <em>Sino Telecom Technology Co.</em>, CNY: ¥180,000<br>
      <strong>Role:</strong> Principal Investigator<br>
      ▪ Raised funding<br>
      ▪ Designed workflow with company<br>
      ▪ Developed detection and recognition algorithms using YOLO
    </li>
    <li>
      <strong>2018–2021</strong> — Object-level visual SLAM for dynamic 3D scene parsing, <em>General Project, NSFC</em>, CNY: ¥620,000<br>
      <strong>Role:</strong> Main Researcher<br>
      ▪ Develop visual odometry in variant lighting<br>
      ▪ Write reports and publish papers
    </li>
    <li>
      <strong>2017–2019</strong> — 3D multi-object tracking in multi-camera systems, <em>Excellent Young Teacher Program, Shanghai Education Commission</em>, CNY: ¥50,000<br>
      <strong>Role:</strong> Principal Investigator<br>
      ▪ Write proposal and raise funding<br>
      ▪ Research and develop 3D tracking algorithms
    </li>
    <li>
      <strong>2018–2020</strong> — Multi-sensor localization for UAV bridge inspection, <em>Essential Project, Shanghai Science Commission</em><br>
      <strong>Role:</strong> Researcher<br>
      ▪ Write proposal and raise funding with Prof. Wu<br>
      ▪ Propose IMU+Vision system and seamless SLAM
    </li>
    <li>
      <strong>2012–2014</strong> — Cardiac cyclic analysis, <em>Joint Project, University of Jena & Hospital</em><br>
      <strong>Role:</strong> Principal Researcher<br>
      ▪ Collaborate with physicians and clinic assistants<br>
      ▪ Design 3D stereo tracking system<br>
      ▪ Record heart data and develop tracking algorithm<br>
      ▪ Provide C++ software, publish and present findings
    </li>
    <li>
      <strong>2022–2024</strong> — 5G + Remote Diagnosis System, <em>Joint work with Guangzhou Zhujiang Hospital</em><br>
      <strong>Role:</strong> Senior Researcher<br>
      ▪ Write proposal and raise funding<br>
      ▪ Lead survival prediction of liver cancer from multi-modal data<br>
      ▪ Collaborate with physicians, analyze EMR and CT images
    </li>
    <li>
      <strong>2018–2021</strong> — Gastric Cancer Diagnosis System, <em>Joint with Shanghai Changzheng Hospital</em><br>
      <strong>Role:</strong> Senior Researcher<br>
      ▪ Collaborate with gastroenterologists<br>
      ▪ Lead CT image segmentation for small tumors<br>
      ▪ Publish related research
    </li>
    <li>
      <strong>2019–2020</strong> — Eye Nystagmus Analysis, <em>Joint with Eye & ENT Hospital of Fudan University</em><br>
      <strong>Role:</strong> Senior Researcher<br>
      ▪ Collaborate with ophthalmologists<br>
      ▪ Analyze nystagmus videos and curves<br>
      ▪ Present findings to partners
    </li>
  </ul>
</section>

<section id="patents" class="bg-white shadow-xl rounded-2xl p-6 mb-6">
  <h2 class="text-2xl font-semibold text-blue-600 border-b pb-2 mb-4">Patents</h2>
  <ul class="list-disc pl-5 space-y-2 text-gray-700">
    <li>Z. Fang, X. Jiang, et al., “An Intelligent Stomach Cancer Staging Approach of CT Images”, Chinese Patent, No. 2021107877777, authorized</li>
    <li>X. Jiang, et al., “An Approach for Detecting Vehicles Breaking the Traffic Rules”, Chinese Patent, No. 201910565608.1, authorized</li>
    <li>X. Jiang, et al., “An Approach for Monocular Visual Odometry”, Chinese Patent, No. 202210570115.9, authorized</li>
    <li>X. Jiang, et al., “An Approach for Airport Pavement Defect Detection and Condition Estimation for Airport Pavements”, Chinese Patent, No. CN114882367A, authorized</li>
    <li>Weibin Wan, Maiyu Ren, Zedong Yu, Jimi Hu, X. Jiang, et al., “An Airport Pavement FOD Detection Method based on Multi-sensor Fusion”, Chinese Patent, No. CN202211300719, substantial examination</li>
    <li>X. Jiang, et al., “A Real-time Localization and Mapping Approach for Large-scale Maps”, Chinese Patent, No. CN117073668A, substantial examination</li>
    <li>Zhijun Fang, Qingyu Tan, X. Jiang, et al., “A Multi-view 3D Reconstruction Approach based on Knowledge Distillation”, Chinese Patent, No. [Pending], substantial examination</li>
    <li>Zhijun Fang, Lehui Zhuang, Jing Tian, X. Jiang, et al., “A Point Cloud Geometry Compression Method based on Asymmetric Autoencoder Structure”, Chinese Patent, No. CN202210902132.8, substantial examination</li>
  </ul>
</section>

<section id="honors-awards" class="bg-white shadow-xl rounded-2xl p-6 mb-6">
  <h2 class="text-2xl font-semibold text-blue-600 border-b pb-2 mb-4">Honors & Awards</h2>
  <ul class="list-disc pl-5 space-y-2 text-gray-700">
    <li>
      <strong>2024.9</strong> — China Aeronautical Science and Technology Award<br>
      <span class="ml-4">Project Name: Key Technologies for Indoor Intelligent Detection and Application of Structural Damage in Civil Aircraft</span><br>
      <span class="ml-4">Award: Third Prize for Scientific and Technological Progress</span><br>
      <span class="ml-4">Certificate Number: HKJ2024J-03-10-RO6, The China Aeronautical Society</span>
    </li>
    <li>
      <strong>2020</strong> — Shanghai Scientific and Technological Progress Award<br>
      <span class="ml-4">Awarding Organization: Shanghai Municipal People's Government, Second Prize</span><br>
      <span class="ml-4">Title: Key Technologies and Industrialization of Cross-Camera Intelligent Video Processing and Analysis</span><br>
      <span class="ml-4">Brief description: We did a lot of work in developing better algorithms for cross-camera video processing tasks. By deeply collaborating with enterprises, we solved practical problems and helped them achieve high profit.</span>
    </li>
    <li><strong>2020</strong> — Postgraduate Work Contribution Award, SUES</li>
    <li><strong>2018 & 2022</strong> — Excellent Teacher Award, SUES</li>
    <li><strong>2015–2016</strong> — German Academic Exchange Service (DAAD) Scholarship</li>
    <li><strong>2004–2006</strong> — Second Prize Scholarship, China University of Mining and Technology</li>
    <li><strong>2004</strong> — Third Prize in the Math Competition held by Jiangsu Province</li>
  </ul>
</section>

<section id="service" class="bg-white shadow-xl rounded-2xl p-6 mb-6">
  <h2 class="text-2xl font-semibold text-blue-600 border-b pb-2 mb-4">Service</h2>
  <ul class="list-disc pl-5 space-y-2 text-gray-700">
    <li><strong>PC Member</strong>: The Fifth International Conference of Pioneering Computer Scientists, Engineers, and Educators (ICPCSEE’19), The 36th International Conference on Industrial, Engineering & Other Applications of Applied Intelligent Systems (IEA/AIE 2023)</li>
    <li><strong>TPC Member</strong>: International Conference on Computer Vision and Image Processing (CVIP 2024), International Conference on Human-Computer Interaction and Virtual Reality (HCIVR 2024)</li>
    <li><strong>Reviewer</strong>: IEEE Transactions on Multimedia (TMM), IEEE Transactions on Image Processing (TIP), IEEE Transactions on Intelligent Transportation Systems (TITS), IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), IEEE International Conference on Multimedia and Expo (ICME), IEEE International Conference on Image Processing (ICIP), Knowledge-Based Systems (KBS), Pattern Recognition (PR), Applied Intelligence, etc.</li>
  </ul>
</section>

<section id="languages" class="bg-white shadow-xl rounded-2xl p-6 mb-6">
  <h2 class="text-2xl font-semibold text-blue-600 border-b pb-2 mb-4">Languages</h2>
  <ul class="list-disc pl-5 space-y-2 text-gray-700">
    <li><strong>Chinese</strong>: Native</li>
    <li><strong>English</strong>: Proficient</li>
    <li><strong>German</strong>: Basic (A2)</li>
  </ul>
</section>

    <!-- Footer -->
    <footer class="text-center text-gray-600 mt-10">
      <p>&copy; 2025 Xiaoyan Jiang. All rights reserved. | <a href="mailto:xiaoyan.jiang@outlook.com" class="text-blue-600">Contact Me</a></p>
    </footer>

  </div>
</body>

</html>
